p8105_hw6_lg3450
================

first we load all necessary libraries:

``` r
library(tidyverse)
library(modelr)
library(broom)
library(patchwork)
```

# Problem1

**The Washington Post has gathered data on homicides in 50 large U.S.
cities and made the data available through a GitHub repository here. You
can read their accompanying article here.**

- **Q1.1: Create a city_state variable (e.g. “Baltimore, MD”), and a
  binary variable indicating whether the homicide is solved. Omit cities
  Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report
  victim race. Also omit Tulsa, AL – this is a data entry mistake. For
  this problem, limit your analysis those for whom victim_race is white
  or black. Be sure that victim_age is numeric.**

We first clean the dataset based on the requirements.

``` r
homicide_df = 
  read_csv("../homicide-data.csv") |>   
  mutate(
    # create city_state variable
    city_state = str_c(city, ", ", state),
    # add binary indicator
    resolved = as.numeric(disposition == "Closed by arrest"),
    # make victim_age numeric
    victim_age = as.numeric(victim_age)) |> 
  # omit 4 cities & limit analysis to White and Black
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"))
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

- **Q1.2: For the city of Baltimore, MD, use the glm function to fit a
  logistic regression with resolved vs unresolved as the outcome and
  victim age, sex and race as predictors. Save the output of glm as an R
  object; apply the broom::tidy to this object; and obtain the estimate
  and confidence interval of the adjusted odds ratio for solving
  homicides comparing male victims to female victims keeping all other
  variables fixed.**

``` r
# fit the logistic regression model for Baltimore, MD
baltimore_glm = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(resolved ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_lower = exp(conf.low),
    OR_CI_upper = exp(conf.high)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |> 
  knitr::kable(
    digits = 3,
    col.names = c("estimated OR", "95% CI Lower", "95% CI Upper"),
    caption = "Table1: Estimate of Adjusted Odds Ratio for Male vs. Female Victims in Baltimore, MD", 
    align = "c")
```

| estimated OR | 95% CI Lower | 95% CI Upper |
|:------------:|:------------:|:------------:|
|    0.426     |    0.324     |    0.558     |

Table1: Estimate of Adjusted Odds Ratio for Male vs. Female Victims in
Baltimore, MD

The adjusted odds ratio for solving homicides comparing male victims to
female victims in Baltimore is 0.426 (95% CI: 0.324, 0.558). This
indicates that, holding victim age and race constant, homicides with
male victims are significantly less likely to be resolved than those
with female victims. Specifically, the odds of resolution for a male
victim are approximately 43% of the odds for a female victim.

- **Q1.3: Now run glm for each of the cities in your dataset, and
  extract the adjusted odds ratio (and CI) for solving homicides
  comparing male victims to female victims. Do this within a “tidy”
  pipeline, making use of purrr::map, list columns, and unnest as
  necessary to create a dataframe with estimated ORs and CIs for each
  city.**

``` r
# run glm for each city using map
city_glm_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    # fit the logistic regression model for each city
    models = map(data, \(df) glm(resolved ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    
    # tidy the output of each model and get CIs
    tidy_results = map(models, \(mod) broom::tidy(mod, conf.int = TRUE))) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_results) |> 
  mutate(
    # convert log-odds to Odds Ratios
    OR = exp(estimate), 
    OR_CI_upper = exp(conf.high),
    OR_CI_lower = exp(conf.low)) |> 
  # filter for the term of interest (Male vs Female)
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper) |> 
  # sort by Odds Ratio (lowest to highest)
  arrange(OR)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `tidy_results = map(models, function(mod) broom::tidy(mod,
    ##   conf.int = TRUE))`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
# display the table
city_glm_results |> 
  slice(1:10) |>
  knitr::kable(
    digits = 3,
    col.names = c("City", "estimated OR", "95% CI Lower", "95% CI Upper"),
    caption = "Table 2: Odds Ratios for Solving Homicides (Male vs. Female Victims) by City",
    align = "c")
```

|      City       | estimated OR | 95% CI Lower | 95% CI Upper |
|:---------------:|:------------:|:------------:|:------------:|
|  New York, NY   |    0.262     |    0.133     |    0.485     |
| Baton Rouge, LA |    0.381     |    0.204     |    0.684     |
|    Omaha, NE    |    0.382     |    0.199     |    0.711     |
| Cincinnati, OH  |    0.400     |    0.231     |    0.667     |
|   Chicago, IL   |    0.410     |    0.336     |    0.501     |
| Long Beach, CA  |    0.410     |    0.143     |    1.024     |
|  San Diego, CA  |    0.413     |    0.191     |    0.830     |
|  Baltimore, MD  |    0.426     |    0.324     |    0.558     |
| Pittsburgh, PA  |    0.431     |    0.263     |    0.696     |
|   Denver, CO    |    0.479     |    0.233     |    0.962     |

Table 2: Odds Ratios for Solving Homicides (Male vs. Female Victims) by
City

- **Q1.4: Create a plot that shows the estimated ORs and CIs for each
  city. Organize cities according to estimated OR, and comment on the
  plot.**

``` r
# create plot showing the ORs and CIs for each city
city_glm_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  geom_hline(yintercept = 1, linetype = "dashed", color = "orange") +
  coord_flip() +
  labs(
    title = "Odds Ratios for Solving Homicides (Male vs. Female Victims)",
    x = "City",
    y = "Odds Ratio (Male vs. Female)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

![](p8105_hw6_lg3450_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

The plot illustrates that for the vast majority of cities, the estimated
odds ratio (OR) is less than 1, indicating that homicides with male
victims are less likely to be resolved than those with female victims,
after adjusting for victim age and race.

New York, NY has the lowest Odds Ratio, suggesting the largest disparity
where male cases are significantly less likely to be solved.

For cities where the 95% confidence intervals do not contain the null
value of 1 (the orange dashed line) (such as Baltimore, Chicago, and
Philadelphia), the difference in resolution rates between genders is
statistically significant.

A few cities (such as Albuquerque, Stockton, and Fresno) have 95%
confidence interval that cross the line of 1. For these locations, we
cannot conclude there is a statistically significant difference in
homicide resolution rates between genders.

# Problem2

first we import the Central Park weather data:

``` r
library(p8105.datasets)
data("weather_df")
set.seed(1)

central_park_df = 
  weather_df |> 
  filter(name == "CentralPark_NY") |> 
  mutate(
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax),
    prcp = as.numeric(prcp)) |> 
  select(name, id, everything())
```

# Problem3

**In this problem, you will analyze data gathered to understand the
effects of several variables on a child’s birthweight. This dataset,
available here, consists of roughly 4000 children.**

- **Q3.1: Load and clean the data for regression analysis (i.e. use
  appropriate variable names, convert numeric to factor where
  appropriate, check for the presence of missing data, etc.).**

``` r
birthweight_df = 
  read_csv("../birthweight.csv") |> 
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex, 
                     levels = c(1, 2), 
                     labels = c("Male", "Female")),
    frace = factor(frace, 
                   levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    
    mrace = factor(mrace, 
                   levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    
    malform = factor(malform, 
                     levels = c(0, 1), 
                     labels = c("Absent", "Present")))
birthweight_df |> 
  map(~sum(is.na(.)))
```

    ## $babysex
    ## [1] 0
    ## 
    ## $bhead
    ## [1] 0
    ## 
    ## $blength
    ## [1] 0
    ## 
    ## $bwt
    ## [1] 0
    ## 
    ## $delwt
    ## [1] 0
    ## 
    ## $fincome
    ## [1] 0
    ## 
    ## $frace
    ## [1] 0
    ## 
    ## $gaweeks
    ## [1] 0
    ## 
    ## $malform
    ## [1] 0
    ## 
    ## $menarche
    ## [1] 0
    ## 
    ## $mheight
    ## [1] 0
    ## 
    ## $momage
    ## [1] 0
    ## 
    ## $mrace
    ## [1] 0
    ## 
    ## $parity
    ## [1] 0
    ## 
    ## $pnumlbw
    ## [1] 0
    ## 
    ## $pnumsga
    ## [1] 0
    ## 
    ## $ppbmi
    ## [1] 0
    ## 
    ## $ppwt
    ## [1] 0
    ## 
    ## $smoken
    ## [1] 0
    ## 
    ## $wtgain
    ## [1] 0

- **Q3.2: Propose a regression model for birthweight. This model may be
  based on a hypothesized structure for the factors that underly
  birthweight, on a data-driven model-building process, or a combination
  of the two. Describe your modeling process and show a plot of model
  residuals against fitted values – use add_predictions and
  add_residuals in making this plot.**
